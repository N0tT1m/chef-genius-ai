# ChefGenius FLAN-T5 Recipe Generator Demo

A complete delivery system showcasing your optimized FLAN-T5-Large recipe generation model.

## ğŸš€ Quick Start

**One-click demo launch:**
```bash
python start_demo.py
```

This automatically:
- Checks dependencies
- Starts the FastAPI backend (port 8000)
- Serves the demo interface (port 3000)
- Opens your browser to the demo

## ğŸ¯ Demo Features

### Model Showcase
- **FLAN-T5-Large (770M parameters)** - Google's instruction-tuned model
- **RTX 4090 optimized** - Hardware-specific performance tuning
- **Real-time generation** - Sub-10 second recipe creation
- **Multi-modal inputs** - Ingredients, cuisine, dietary restrictions

### Interactive Interface
- **Ingredient input** - Natural language ingredient lists
- **Cuisine selection** - 8+ cuisine types supported  
- **Difficulty levels** - Easy/Medium/Hard complexity
- **Dietary filters** - Vegetarian, vegan, gluten-free, etc.
- **Real-time preview** - Live recipe generation with progress

### Technical Capabilities
- **Advanced prompting** - Optimized instruction templates for FLAN-T5
- **Structured output** - Consistent recipe formatting
- **Fallback modes** - Graceful degradation without backend
- **Performance monitoring** - Real-time generation metrics

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Demo UI       â”‚â”€â”€â”€â–¶â”‚  FastAPI Backend â”‚â”€â”€â”€â–¶â”‚ FLAN-T5 Model   â”‚
â”‚  (port 3000)    â”‚    â”‚   (port 8000)    â”‚    â”‚  Generation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backend (`/backend/`)
- **FastAPI** - Modern async API framework
- **Recipe Generation Service** - FLAN-T5 model integration
- **Database** - SQLAlchemy with PostgreSQL support
- **Performance Optimization** - Hardware-specific acceleration

### Demo Interface (`demo.html`)
- **Modern UI** - Responsive design with CSS Grid
- **Real-time updates** - WebSocket-like experience
- **Error handling** - Graceful offline fallbacks
- **Progress tracking** - Visual generation feedback

### Training Scripts (`/cli/`)
- **Optimized training** - RTX 4090 specific configurations
- **Dataset integration** - 2.4M+ recipes from multiple sources
- **Monitoring** - W&B, Discord, SMS notifications
- **Performance tuning** - Mixed precision, gradient accumulation

## ğŸ“Š Training Configuration

Your optimized FLAN-T5 training setup:

```python
# Hardware: RTX 4090 (24GB VRAM) + Ryzen 9 3900X
model = "google/flan-t5-large"  # 770M parameters
batch_size = 3
gradient_accumulation_steps = 8
precision = "bf16"  # Mixed precision
learning_rate = 5e-5
max_length = 512
```

## ğŸ® Usage Examples

### Basic Generation
```
Ingredients: chicken breast, garlic, olive oil
Cuisine: Italian
Difficulty: Medium
â†’ Generates complete Italian chicken recipe
```

### Advanced Generation  
```
Ingredients: chickpeas, spinach, coconut milk, curry powder
Cuisine: Indian
Dietary: Vegan
Servings: 6
â†’ Generates vegan Indian curry with scaling
```

## ğŸ”§ Manual Backend Start

If you want to run components separately:

```bash
# Start backend
cd backend
python -m uvicorn app.main:app --reload --port 8000

# Serve demo (in separate terminal)
python -m http.server 3000
# Then visit: http://localhost:3000/demo.html
```

## ğŸ“ˆ Performance Metrics

- **Generation time**: <10 seconds per recipe
- **Token throughput**: 50+ tokens/second
- **Memory usage**: 12GB VRAM (FLAN-T5-Large)
- **Batch processing**: 3 recipes simultaneously

## ğŸ”— API Endpoints

- `GET /health` - Service health check
- `POST /api/v1/recipes/generate` - Generate new recipe
- `GET /api/v1/recipes/` - List generated recipes
- `GET /docs` - Interactive API documentation

## ğŸ¯ Training Your Model

To train your own FLAN-T5 model:

```bash
# Run optimized training
python cli/train_t5_example.py

# Or with full monitoring
python cli/complete_optimized_training.py
```

## ğŸŒŸ Next Steps

1. **Train the model** - Run your optimized training script
2. **Deploy to production** - Use Docker containers provided
3. **Scale infrastructure** - Add load balancing and caching
4. **Enhance features** - Add image generation, nutrition analysis

## ğŸ“ Demo Presentation Points

- **Model sophistication** - 770M parameter instruction-tuned LLM
- **Training optimization** - Hardware-specific performance tuning  
- **Real-world application** - Complete recipe generation pipeline
- **Production ready** - Database integration, API design, monitoring
- **Scalable architecture** - Microservices with Docker support

---

**Ready to impress?** Run `python start_demo.py` and showcase your AI cooking assistant!