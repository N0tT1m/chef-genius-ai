# ChefGenius ğŸ³

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Next.js](https://img.shields.io/badge/Next.js-14-black)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-ready-blue)](https://www.docker.com/)
[![RAG](https://img.shields.io/badge/RAG-Enhanced-purple)](https://www.anthropic.com/)
[![MCP](https://img.shields.io/badge/MCP-Enabled-orange)](https://www.anthropic.com/)

ChefGenius is a next-generation AI-powered cooking platform featuring advanced **RAG (Retrieval Augmented Generation)** and **MCP (Model Context Protocol)** architecture. Trained on 4.1M+ recipes with sophisticated vector search, multi-server orchestration, and real-time monitoring, it delivers intelligent recipe generation, ingredient substitution, meal planning, and comprehensive culinary assistance.

## âœ¨ Key Features

### ğŸ§  Advanced AI Architecture
- **ğŸ¤– FLAN-T5-XL Recipe Generation**: Fine-tuned 3B parameter models trained on 2.2M+ recipes with RTX 4090 optimization
- **ğŸ” RAG-Enhanced Search**: Hybrid semantic + keyword search with Weaviate vector database
- **ğŸ”— MCP Server Orchestration**: Multi-server architecture with circuit breakers and fault tolerance
- **ğŸ’¾ Intelligent Caching**: Redis-backed caching with 90%+ hit rates for optimal performance
- **ğŸ“Š Real-time Training Monitor**: Live recipe generation testing during model training
- **ğŸ¦€ Rust Performance Core**: High-performance PyO3 acceleration for 5-15x speed improvements
- **ğŸš¨ Model Drift Detection**: Advanced statistical monitoring for production model health

### ğŸ³ Culinary Intelligence
- **ğŸ”„ Smart Substitutions**: ML-powered ingredient replacement with dietary restriction support
- **ğŸ“Š Nutritional Analysis**: Comprehensive nutrition tracking with health classification
- **ğŸŒ Global Cuisine Support**: Multi-cuisine knowledge base with ingredient compatibility
- **ğŸ›’ Meal Planning**: AI-generated meal plans with shopping list optimization

### ğŸ”§ Production-Ready Infrastructure
- **ğŸ“ˆ Real-time Monitoring**: Comprehensive health checks, metrics, and Discord alerting
- **ğŸ³ Docker Deployment**: Full containerization with production-ready configurations
- **âš¡ High Performance**: Optimized for RTX 4090 with BF16 precision and 24GB VRAM utilization
- **ğŸ”’ Enterprise Security**: JWT authentication, rate limiting, and security best practices
- **ğŸ¯ Model Observability**: Advanced drift detection, performance monitoring, and quality tracking
- **ğŸš€ Rust Acceleration**: PyO3-based core for 10-50x performance improvements in ML operations

## ğŸ—ï¸ System Architecture

### ğŸ”„ RAG + MCP Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE                           â”‚
â”‚                 Frontend (React/Next.js)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND API                               â”‚
â”‚              (FastAPI + MCP Client)                        â”‚
â”‚            + Rust Core + Drift Monitoring                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ MCP Protocol
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MCP SERVERS                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Recipe    â”‚ â”‚ Knowledge   â”‚ â”‚    Tool     â”‚            â”‚
â”‚  â”‚   Server    â”‚ â”‚   Server    â”‚ â”‚   Server    â”‚            â”‚
â”‚  â”‚ (T5-Large)  â”‚ â”‚   (RAG)     â”‚ â”‚ (Utilities) â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DATA LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Weaviate   â”‚ â”‚    Redis    â”‚ â”‚   Recipe    â”‚            â”‚
â”‚  â”‚ (Vectors)   â”‚ â”‚  (Cache)    â”‚ â”‚  Database   â”‚            â”‚
â”‚  â”‚             â”‚ â”‚             â”‚ â”‚ (4.1M recipes)           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ–¥ï¸ Frontend Stack
- **Framework**: Next.js 14 with TypeScript and App Router
- **Styling**: TailwindCSS with Headless UI components
- **State Management**: React Query for server state, Zustand for client state
- **Real-time Updates**: WebSocket integration for live training progress
- **Performance**: React Suspense and streaming for optimal loading

### âš™ï¸ Backend Stack
- **API Framework**: FastAPI with automatic OpenAPI documentation
- **MCP Integration**: Advanced Model Context Protocol orchestration
- **Authentication**: JWT tokens with refresh mechanism and role-based access
- **Monitoring**: Comprehensive health checks with Prometheus metrics
- **Circuit Breakers**: Fault tolerance with automatic failover

### ğŸ§  AI/ML Infrastructure
- **Recipe Generation**: FLAN-T5-XL (3B parameters) fine-tuned on 2.2M recipes
- **Vector Database**: Weaviate with hybrid semantic + keyword search populated with 2.2M recipes
- **Knowledge Graph**: NetworkX-based ingredient relationship mapping
- **Hardware Optimization**: RTX 4090 with BF16 precision, batch size 12, profiling enabled
- **Model Serving**: Multi-server architecture with load balancing
- **Real-time Monitoring**: Enhanced training monitor with live recipe generation testing
- **Rust Performance Engine**: PyO3-based acceleration for ML inference, vector search, and statistical analysis
- **Model Drift Detection**: Kolmogorov-Smirnov, PSI, Jensen-Shannon divergence for production model health

### ğŸ“Š Data Layer
- **Vector Storage**: Weaviate for semantic search and embeddings
- **Caching**: Redis for high-performance response caching
- **Recipe Database**: Structured storage for 4.1M recipe dataset
- **Session Management**: Persistent user sessions and preferences

### ğŸ³ Infrastructure
- **Containerization**: Full Docker deployment with production configurations
- **Orchestration**: Docker Compose with health checks and auto-restart
- **Monitoring**: Grafana dashboards with real-time system metrics
- **Alerting**: Discord webhook integration for training and system alerts

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- 16GB+ RAM (24GB recommended for RTX 4090)
- NVIDIA GPU with CUDA support (optional but recommended)
- Python 3.11+

### ğŸ”¥ RAG + MCP Deployment

1. **Clone and Setup**
   ```bash
   git clone https://github.com/N0tT1m/chef-genius-ai.git
   cd chef-genius-ai
   chmod +x Makefile.mcp
   ```

2. **Quick Start (All Services)**
   ```bash
   # Builds and starts everything including Weaviate, MCP servers, monitoring
   make -f Makefile.mcp quick-start
   
   # Or step by step
   make -f Makefile.mcp build
   make -f Makefile.mcp up
   ```

3. **Verify Deployment**
   ```bash
   # Check all services
   make -f Makefile.mcp health
   
   # Test MCP servers
   make -f Makefile.mcp test-mcp
   
   # Monitor system
   make -f Makefile.mcp logs
   ```

### ğŸŒ Service Access Points

| Service | URL | Purpose |
|---------|-----|---------|
| **Frontend** | http://localhost:3000 | Main application |
| **Backend API** | http://localhost:8000 | REST API + MCP orchestration + Rust acceleration |
| **Recipe Server** | http://localhost:8001 | T5-Large recipe generation |
| **Knowledge Server** | http://localhost:8002 | RAG knowledge retrieval |
| **Tool Server** | http://localhost:8003 | Utility integrations |
| **Weaviate** | http://localhost:8080 | Vector database |
| **Grafana** | http://localhost:3001 | Monitoring dashboard |
| **Prometheus** | http://localhost:9090 | Metrics collection |
| **TensorBoard** | http://localhost:6006 | Training monitoring (Docker) |

### Development Setup

<details>
<summary>Click to expand development setup instructions</summary>

#### Backend Development
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup databases (PostgreSQL, MongoDB, Redis, Elasticsearch must be running)
createdb chefgenius
alembic upgrade head

# Start development server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend Development
```bash
cd frontend
npm install

# Start development server
npm run dev
```

#### Start Required Services
```bash
# Using Docker for databases only
docker-compose up -d postgres mongodb redis elasticsearch
```

</details>

## ğŸ¤– FLAN-T5-XL Model Training & Dual Tokenizer System

### ğŸ”¤ Dual Tokenizer Architecture

**Enterprise-grade specialized tokenizers for different domains:**

#### **ğŸ­ Enterprise B2B Tokenizer (50,000 vocab)**
- **Commercial kitchens** and large-scale food service operations
- **Batch cooking** terminology (100+ servings)
- **Food safety compliance** (HACCP, temperature logs, procedures)
- **Commercial equipment** (combi_oven, blast_chiller, tilting_braising_pan)
- **Cost control** and yield management
- **Supply chain** and inventory management

#### **ğŸ  Consumer End User Tokenizer (32,000 vocab)**
- **Home cooking** and family-friendly recipes
- **Casual cooking** techniques and home equipment
- **Dietary preferences** and lifestyle choices
- **Quick weeknight** meals and meal prep
- **Budget-conscious** cooking approaches
- **Seasonal** and occasion-based recipes

#### **ğŸš€ Tokenizer Training Commands**

```bash
# Train both tokenizers in parallel (fastest)
python cli/dual_tokenizer_manager.py --train --parallel --discord-webhook "YOUR_WEBHOOK"

# Train individual tokenizers
python cli/enterprise_b2b_tokenizer.py --vocab-size 50000
python cli/consumer_end_user_tokenizer.py --vocab-size 32000

# Compare tokenizer performance
python cli/dual_tokenizer_manager.py --compare --load

# Create deployment package
python cli/dual_tokenizer_manager.py --deploy
```

### ğŸ§ª Comprehensive Checkpoint Testing

**Enterprise-grade model testing with edge cases and quality assessment:**

```bash
# Test all model checkpoints with comprehensive scenarios
python cli/comprehensive_checkpoint_tester.py --models-dir /path/to/models

# Test specific checkpoint
python cli/comprehensive_checkpoint_tester.py --checkpoint /path/to/checkpoint-1000

# Test with custom model directory (Docker training)
python cli/comprehensive_checkpoint_tester.py --models-dir /training/models --parallel 2
```

**Test Coverage:**
- **Normal Cases**: Traditional recipes, healthy meals, gourmet dishes
- **Edge Cases**: Molecular gastronomy, extreme dietary restrictions, emergency cooking
- **Technical Cases**: Competition dishes, fermentation, high-altitude baking
- **Quality Metrics**: Structure validation, ingredient coverage, instruction clarity

### ğŸ—‘ï¸ Removed Legacy Files

**The following files have been removed in favor of the new enterprise-grade system:**

- âŒ `training_monitor.py` â†’ Replaced by `comprehensive_checkpoint_tester.py`
- âŒ `training_monitor_enhanced.py` â†’ Integrated into `complete_optimized_training.py`
- âŒ `rust_training_monitor.py` â†’ Merged into main training pipeline
- âŒ `train_with_monitoring_example.py` â†’ Superseded by production training script
- âŒ `fast_rust_tokenizer.py` â†’ Replaced by dual tokenizer system
- âŒ `comprehensive_recipe_tokenizer.py` â†’ Split into specialized B2B/Consumer tokenizers
- âŒ `b2b_recipe_testing.py` â†’ Enhanced functionality moved to checkpoint tester

**Migration Guide:**
- Use `complete_optimized_training.py` for all model training
- Use `comprehensive_checkpoint_tester.py` for model validation
- Use `dual_tokenizer_manager.py` for tokenizer management
- Enterprise B2B models: use `enterprise_b2b_tokenizer.py`
- Consumer models: use `consumer_end_user_tokenizer.py`

## ğŸš€ Enterprise Model Training

### ğŸ³ Docker Training (Recommended for Maximum Performance)

**Production-ready Docker training with Rust-powered data loading + GPU acceleration**

#### **âš¡ Prerequisites & Setup**

**System Requirements:**
- **Docker** 20.10+ with GPU support
- **NVIDIA Container Toolkit** installed
- **16GB+ System RAM** (32GB recommended)
- **GPU**: RTX 3080/4080/4090 (16GB+ VRAM) or A100/H100

**1. Install NVIDIA Container Toolkit (First-time setup)**
```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

# Test GPU access
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi
```

**2. Build Training Container (One-time)**
```bash
# Clone repository
git clone https://github.com/your-username/chef-genius.git
cd chef-genius

# Build optimized training container with Rust acceleration
docker build -f Dockerfile.training -t chef-genius-training:latest .

# Verify Rust modules compiled successfully
docker run --rm chef-genius-training:latest python test_rust_import.py
# Expected output: âœ… chef_genius_dataloader imported successfully
```

#### **ğŸš€ Training Commands**

**Production Training (GPU + Rust Acceleration)**
```bash
# Full production training with optimal settings and dual tokenizer support
docker run --gpus all \
  -v $(pwd)/models:/workspace/models \
  -v $(pwd)/logs:/workspace/logs \
  --name chef-genius-training
  chef-genius-training:latest \
  python cli/complete_optimized_training.py \
  --epochs 5 \
  --batch-size 16 \
  --gradient-accumulation-steps 2 \
  --enable-mixed-precision \
  --enable-profiling \
  --profile-schedule "wait=2;warmup=2;active=5;repeat=3" \
  --model-output ../models/recipe_generation_flan-t5-large \
  --pretrained-model google/flan-t5-large \
  --alert-phone "+1234567890" \
  --discord-webhook "YOUR_DISCORD_WEBHOOK_URL"
```

**Resume from Checkpoint**
```bash
# Resume training from existing checkpoint
docker run --rm --gpus all \
  -v $(pwd)/models:/workspace/models \
  chef-genius-training:latest \
  python cli/complete_optimized_training.py \
  --resume-from-checkpoint ../models/recipe_generation_flan-t5-large/checkpoint-1000 \
  --epochs 5 \
  --batch-size 16 \
  --model-output ../models/recipe_generation_flan-t5-large \
  --pretrained-model google/flan-t5-large
```

**Development Training (CPU-only)**
```bash
# Development/testing without GPU requirements
docker run --rm \
  -v $(pwd)/models:/workspace/models \
  chef-genius-training:latest \
  python cli/complete_optimized_training.py \
  --disable-compilation \
  --epochs 2 \
  --batch-size 4 \
  --model-output ../models/recipe_generation_flan-t5-large \
  --pretrained-model google/flan-t5-large
```

#### **ğŸ¦€ Performance Benefits**
- **âœ… Rust Data Loading**: 5-15x faster data processing with PyO3 acceleration
- **âœ… GPU torch.compile()**: 15-25% speed boost when CUDA is available  
- **âœ… RTX 4090 Optimizations**: TF32, BF16, Flash Attention, 24GB VRAM utilization
- **âœ… Unified Dataset Loader**: 2.4M+ recipes across 9 datasets with background threading
- **âœ… Smart Checkpointing**: Automatic checkpoint saving every 500 steps
- **âœ… Real-time Monitoring**: TensorBoard + W&B + Discord + SMS notifications
- **âœ… Automatic Fallbacks**: CPU-only mode for development/testing

#### **ğŸ“Š Expected Performance**
| Hardware | Batch Size | Training Time | Peak VRAM | Rust Speedup |
|----------|------------|---------------|-----------|---------------|
| **RTX 4090 (24GB)** | 16 | **18-24 hours** | ~20GB | ğŸ¦€ 5-15x faster |
| **RTX 4080 (16GB)** | 12 | 24-32 hours | ~14GB | ğŸ¦€ 5-15x faster |
| **RTX 3080 (10GB)** | 8 | 32-48 hours | ~9GB | ğŸ¦€ 5-15x faster |
| **CPU-only** | 4 | 7-14 days | N/A | ğŸ Python fallback |

#### **ğŸ“Š Real-time Training Monitor**
Training provides comprehensive real-time feedback:

```bash
# Rust acceleration confirmation:
ğŸ§ª Testing Rust imports step by step...
âœ… chef_genius_dataloader imported successfully
âœ… All required functions available
âœ… fast_dataloader imported, RUST_AVAILABLE: True

# Dataset loading with Rust:
ğŸ¦€ Creating Rust-powered loaders for 9 datasets...
ğŸ¦€ Using Rust-powered data loader for maximum performance!
  âœ… recipe_nlg/RecipeNLG_dataset.csv (2188.7MB)
  âœ… PP_recipes.csv/PP_recipes.csv (195.4MB)
  âœ… epi_r.csv/epi_r.csv (52.7MB)
ğŸš€ Started 9 background loading threads

# GPU optimization status:
ğŸš€ Enabling torch.compile for GPU acceleration...
âš ï¸  Skipping torch.compile (CPU-only environment detected)

# Training progress:
Epoch 1/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [01:23<00:00, 30.1it/s]
Train Loss: 0.234 | GPU Memory: 18.2GB/24GB | Rust Speedup: 12.3x
```

#### **ğŸ”” Notifications & Monitoring**

**Discord Integration**
```bash
# Create Discord webhook (optional but recommended)
# 1. Go to Discord Server Settings â†’ Integrations â†’ Webhooks
# 2. Create webhook, copy URL
# 3. Add to training command:
--discord-webhook "https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_TOKEN"

# Automatic notifications for:
# â€¢ ğŸš€ Training started with hardware specs
# â€¢ ğŸ“Š Progress updates every epoch  
# â€¢ âœ… Training completion with metrics
# â€¢ âŒ Error alerts with stack traces
# â€¢ âš ï¸ Hardware warnings (temperature, memory)
```

**SMS Alerts (Optional)**
```bash
# Add phone number for critical alerts:
--alert-phone "+1234567890"

# Supported services:
# â€¢ TextBelt (free, 1 SMS/day)
# â€¢ Twilio (paid, set TWILIO_* env vars)
# â€¢ Email-to-SMS gateways
```

#### **ğŸ“ Volume Mounting & Persistence**

```bash
# Recommended volume mounts for production:
docker run --rm --gpus all \
  -v $(pwd)/models:/workspace/models \          # Model checkpoints
  -v $(pwd)/logs:/workspace/logs \              # Training logs  
  -v $(pwd)/data:/workspace/cli/data \          # Dataset cache
  -v /tmp:/tmp \                                # Temporary files
  chef-genius-training:latest \
  python cli/complete_optimized_training.py \
  # ... training arguments
```

#### **ğŸ”„ Managing Long-running Training (18-24 hours)**

**Option 1: Using screen (Recommended)**
```bash
# Start a persistent screen session
screen -S chef-training

# Run training command inside screen
docker run --rm --gpus all \
  -v $(pwd)/models:/workspace/models \
  chef-genius-training:latest \
  python cli/complete_optimized_training.py \
  --epochs 5 --batch-size 16 --gradient-accumulation-steps 2 \
  --model-output ../models/recipe_generation_flan-t5-large \
  --pretrained-model google/flan-t5-large

# Detach from screen: Ctrl+A, then D
# Reattach later: screen -r chef-training
# List sessions: screen -ls
```

**Option 2: Using tmux**
```bash
# Create new tmux session
tmux new-session -d -s chef-training

# Run training in tmux
tmux send-keys -t chef-training "docker run --rm --gpus all -v \$(pwd)/models:/workspace/models chef-genius-training:latest python cli/complete_optimized_training.py --epochs 5 --batch-size 16 --gradient-accumulation-steps 2 --model-output ../models/recipe_generation_flan-t5-large --pretrained-model google/flan-t5-large" Enter

# Attach to session: tmux attach-session -t chef-training
# Detach: Ctrl+B, then D
```

**Option 3: Background with nohup**
```bash
# Run in background with output logging
nohup docker run --rm --gpus all \
  -v $(pwd)/models:/workspace/models \
  chef-genius-training:latest \
  python cli/complete_optimized_training.py \
  --epochs 5 --batch-size 16 --gradient-accumulation-steps 2 \
  --model-output ../models/recipe_generation_flan-t5-large \
  --pretrained-model google/flan-t5-large \
  > training.log 2>&1 &

# Monitor progress: tail -f training.log
# Check process: ps aux | grep docker
```

#### **ğŸ”§ Troubleshooting**

<details>
<summary><strong>ğŸ³ Docker GPU Issues</strong></summary>

```bash
# Check GPU access
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi

# Common fixes:
# 1. Restart Docker daemon
sudo systemctl restart docker

# 2. Reinstall NVIDIA Container Toolkit
sudo apt-get purge nvidia-docker2
sudo apt-get install nvidia-docker2
sudo systemctl restart docker

# 3. Check Docker GPU config
cat /etc/docker/daemon.json
# Should contain: {"default-runtime": "nvidia"}
```

</details>

<details>
<summary><strong>ğŸ¦€ Rust Compilation Issues</strong></summary>

```bash
# Test Rust modules
docker run --rm chef-genius-training:latest python test_rust_import.py

# If Rust import fails:
# 1. Rebuild container without cache
docker build --no-cache -f Dockerfile.training -t chef-genius-training:latest .

# 2. Check build logs
docker build -f Dockerfile.training -t chef-genius-training:latest . 2>&1 | grep -A 10 "Building chef_genius"

# 3. Manual Rust build test
docker run --rm -it chef-genius-training:latest bash
cd /workspace/chef_genius_core && maturin develop --release
```

</details>

<details>
<summary><strong>ğŸ’¾ Memory Issues</strong></summary>

```bash
# Monitor GPU memory during training
watch -n 1 nvidia-smi

# Reduce batch size if OOM:
--batch-size 8              # RTX 3080/4070
--batch-size 12             # RTX 4080  
--batch-size 16             # RTX 4090

# Enable gradient checkpointing for memory efficiency:
--enable-gradient-checkpointing
```

</details>

<details>
<summary><strong>ğŸ”„ Training Resume Issues</strong></summary>

```bash
# List available checkpoints
ls -la models/recipe_generation_flan-t5-large/

# Resume from specific checkpoint
--resume-from-checkpoint ../models/recipe_generation_flan-t5-large/checkpoint-1500

# If resume fails, check checkpoint directory structure:
# âœ… checkpoint-1000/
#    â”œâ”€â”€ config.json
#    â”œâ”€â”€ pytorch_model.bin
#    â”œâ”€â”€ tokenizer.json
#    â””â”€â”€ training_args.bin
```

</details>

#### **âš ï¸ Important Notes**

- **First Training Run**: Download of FLAN-T5-Large (~3GB) may take 10-30 minutes
- **Training Duration**: Expect **18-24 hours** for full 5-epoch training on RTX 4090
- **Initial Setup Time**: First epoch may take longer due to data preprocessing and caching
- **Checkpoint Frequency**: Automatic saves every 500 steps (configurable)
- **Dataset Download**: 2.4M recipes (~4GB) downloaded automatically on first run
- **Progress Visibility**: Significant quality improvements visible after epoch 1 (~4-5 hours)
- **GPU Memory**: Training will auto-adjust batch size if GPU memory insufficient
- **Interruption Safety**: Use Ctrl+C to safely stop training (saves checkpoint)
- **Long-running Process**: Consider using `screen` or `tmux` for persistent sessions

### ğŸš€ RTX 4090 Native Training (Windows/Linux)

**Hardware Configuration**: RTX 4090 (24GB VRAM) + Ryzen 3900X (12 cores)

```bash
cd cli

# FLAN-T5-XL Production Training (3B parameters)
python complete_optimized_training.py \
  --epochs 5 \
  --batch-size 12 \
  --enable-profiling \
  --profile-schedule "wait=2;warmup=2;active=5;repeat=3" \
  --model-output ../models/recipe_generation_flan-t5-xl \
  --pretrained-model google/flan-t5-xl \
  --alert-phone "+1234567890" \
  --discord-webhook "YOUR_WEBHOOK_URL"

# FLAN-T5-Large Training (770M parameters - faster)
python complete_optimized_training.py \
  --epochs 5 \
  --batch-size 12 \
  --model-output ../models/recipe_generation_flan-t5 \
  --pretrained-model google/flan-t5-large \
  --alert-phone "+1234567890" \
  --discord-webhook "YOUR_WEBHOOK_URL"
```

### ğŸ“Š Training with Discord + SMS Alerts

```bash
# Training with real-time Discord and SMS notifications
python train_recipe_model.py \
  --model-type t5 \
  --pretrained-model google/flan-t5-large \
  --model-output ../models/recipe_generation \
  --epochs 5 \
  --batch-size 32 \
  --learning-rate 5e-5 \
  --dataloader-num-workers 12 \
  --enable-mixed-precision \
  --enable-gradient-checkpointing \
  --discord-webhook YOUR_WEBHOOK_URL \
  --alert-phone +18125841533 \
  --notification-interval 2

# Available notification options:
# --discord-webhook URL          Discord webhook for rich notifications
# --alert-phone NUMBER           Phone number for SMS alerts (multiple services)
# --notification-interval N      Send progress updates every N epochs (default: 5)
```

### ğŸ”” Dual Notification System

#### **Discord Notifications (Rich Embeds)**
- **ğŸš€ Training Started**: Model info, dataset size, hardware configuration
- **ğŸ“Š Progress Updates**: Epoch progress, loss metrics, learning rate charts
- **âœ… Training Complete**: Duration, final metrics, performance summary
- **âŒ Error Alerts**: Detailed error messages, stack traces, failed epoch info
- **âš ï¸ Hardware Warnings**: GPU memory, temperature, performance issues

#### **SMS Notifications (Text Messages)**
- **ğŸ“± Training Started**: "Training started: T5-Large, 5 epochs, batch size 32"
- **ğŸ“ˆ Progress Updates**: "Training progress: 40.0% (2/5), Loss: 0.1234"
- **ğŸ‰ Training Complete**: "Training completed! Duration: 4.25h, Final loss: 0.1150"
- **ğŸš¨ Error Alerts**: "Training error at epoch 3: CUDA out of memory..."
- **âš ï¸ Hardware Warnings**: "Hardware warning: GPU temperature high (85Â°C)"

#### **SMS Service Support**
1. **TextBelt** (Free): 1 SMS per day per IP address
2. **Twilio** (Paid): Set environment variables for reliable delivery:
   ```bash
   export TWILIO_ACCOUNT_SID=your_account_sid
   export TWILIO_AUTH_TOKEN=your_auth_token  
   export TWILIO_PHONE_NUMBER=+1234567890
   ```
3. **Email-to-SMS Gateway** (Fallback): Carrier-specific email gateways

### ğŸ§ª Testing Notifications

```bash
# Test your notification setup
python test_sms_discord.py

# Expected output:
# âœ… Discord notification sent successfully! Status: 200
# âœ… SMS sent successfully via TextBelt!
```

### ğŸ”§ Notification Troubleshooting

#### **Discord Issues**
- **Invalid webhook**: Check Discord webhook URL format
- **Rate limited**: Discord allows 30 requests per minute
- **Permission denied**: Ensure webhook has "Send Messages" permission

#### **SMS Issues**  
- **TextBelt quota exceeded**: Free tier = 1 SMS/day per IP
- **Invalid phone number**: Use international format (+1234567890)
- **Carrier blocking**: Some carriers block automated SMS

#### **Fallback Options**
- **Discord only**: Omit `--alert-phone` parameter
- **SMS only**: Omit `--discord-webhook` parameter  
- **No notifications**: Omit both parameters

### ğŸ¯ Training Performance Specs

#### FLAN-T5-XL (Production Model)
- **Model**: FLAN-T5-XL (3B parameters) 
- **Dataset**: 2.2M recipes (unified dataset)
- **Training Time**: ~3-5 days on RTX 4090
- **Memory Usage**: ~18-22GB VRAM with BF16 precision
- **Batch Size**: 12 (optimal for 24GB VRAM)
- **Quality**: Enterprise-grade recipe generation

#### FLAN-T5-Large (Development Model)
- **Model**: FLAN-T5-Large (770M parameters)
- **Dataset**: 2.2M recipes (unified dataset)
- **Training Time**: ~8-12 hours on RTX 4090
- **Memory Usage**: ~8-12GB VRAM with BF16 precision  
- **Batch Size**: 12 (conservative setting)
- **Quality**: High-quality recipe generation

### ğŸ“ˆ Training Monitoring
- **Real-time Metrics**: Loss, learning rate, GPU utilization
- **Discord Alerts**: Start, progress, completion, and error notifications
- **Weights & Biases**: Automatic experiment tracking
- **Hardware Monitoring**: GPU temperature, memory usage, power consumption

### ğŸ”§ Complete Command Example

```bash
# Full RTX 4090 training with Discord notifications and pipeline monitoring
python train_recipe_model.py \
  --model-type t5 \
  --pretrained-model google/flan-t5-large \
  --model-output ../models/recipe_generation \
  --epochs 5 \
  --batch-size 32 \
  --learning-rate 5e-5 \
  --dataloader-num-workers 12 \
  --enable-mixed-precision \
  --enable-gradient-checkpointing \
  --enable-pipeline-monitoring \
  --pipeline-report-interval 2 \
  --discord-webhook "https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_WEBHOOK_TOKEN" \
  --notification-interval 2 \
  --datasets recipe_nlg food_com_recipes_2m allrecipes_250k
```

### ğŸ“Š Data Pipeline Monitoring

Advanced bottleneck detection and performance optimization:

```bash
# Enable comprehensive data pipeline monitoring
--enable-pipeline-monitoring           # Track data loading, collation, throughput
--pipeline-report-interval 3           # Generate reports every 3 epochs
--dataloader-num-workers 12           # Optimize worker count for your CPU
```

#### **Monitored Metrics**
- **ğŸ“ˆ Data Loading Times**: Batch loading performance and bottlenecks
- **âš™ï¸ Collation Performance**: Data preparation and tensor conversion times
- **ğŸš€ Throughput Analysis**: Samples per second, queue sizes, memory usage
- **ğŸ’¾ Cache Performance**: Hit rates, miss patterns, optimization opportunities
- **ğŸ” Error Tracking**: Corrupted samples, loading failures, data quality issues

#### **Automatic Alerts**
- **ğŸŒ Slow Data Loading**: > 2 seconds per batch
- **âš ï¸ Low Throughput**: < 10 samples per second
- **ğŸ’¾ High Memory Usage**: > 85% RAM utilization
- **ğŸ“Š Poor Cache Performance**: < 80% hit rate
- **âŒ Data Errors**: Corrupted or failed samples

#### **Performance Reports**
```
============================================================
DATA PIPELINE PERFORMANCE REPORT
============================================================

ğŸ“Š PERFORMANCE METRICS:
  â€¢ Avg Data Loading Time: 0.245s
  â€¢ Avg Collation Time: 0.089s
  â€¢ Current Throughput: 127.3 samples/sec
  â€¢ Cache Hit Rate: 94.2%
  â€¢ Data Errors: 0

âš ï¸  BOTTLENECKS DETECTED (MEDIUM):
  â€¢ Data collation is slow: 0.89s average (medium severity)

ğŸ’¡ RECOMMENDATIONS:
  â€¢ Optimize data collation function
  â€¢ Use more efficient data structures
  â€¢ Increase DataLoader num_workers
============================================================
```

### Advanced Continual Learning

The platform includes sophisticated continual learning capabilities for ongoing model improvement:

#### 1. Incremental Training
```bash
# Add new recipes to existing model
python cli/incremental_training.py \
  --base-model models/recipe_generation \
  --new-data new_recipes.csv \
  --output-dir models/recipe_generation_v2 \
  --epochs 2 \
  --learning-rate 1e-5
```

#### 2. Online Learning Pipeline
```bash
# Start continuous learning from incoming recipe files
python cli/online_learning_pipeline.py \
  --model-path models/recipe_generation \
  --watch-dir data/incoming \
  --output-dir training_outputs \
  --min-recipes 10 \
  --daemon
```

#### 3. Model Versioning & Management
```bash
# Create model version
python cli/model_versioning.py --model-dir models create \
  --model-path models/recipe_generation_v2 \
  --description "Updated with 1000 new recipes"

# List all versions
python cli/model_versioning.py --model-dir models list

# Rollback to previous version
python cli/model_versioning.py --model-dir models rollback v1
```

#### 4. Catastrophic Forgetting Prevention
```bash
# Train with EWC and replay buffer
python cli/catastrophic_forgetting_prevention.py \
  --model-path models/recipe_generation \
  --new-data new_recipes.json \
  --output-dir models/recipe_generation_continual \
  --method both \
  --ewc-lambda 1000.0 \
  --replay-buffer-size 1000
```

### ğŸ“Š Real-time Training Monitoring

```bash
# Enhanced real-time training monitoring with beautiful output
python cli/training_monitor_enhanced.py \
  --model-dir ../models/recipe_generation_flan-t5 \
  --monitor \
  --interval 5

# Test specific checkpoint with enhanced prompts
python cli/training_monitor_enhanced.py \
  --model-dir ../models/recipe_generation_flan-t5/checkpoint-1000

# Monitor during training (separate terminal)
python cli/training_monitor_enhanced.py \
  --model-dir ../models/recipe_generation_flan-t5 \
  --monitor \
  --interval 10 \
  --max-length 512
```

### ğŸ—„ï¸ RAG Database Population

```bash
# Start Weaviate vector database
docker run -p 8080:8080 semitechnologies/weaviate:latest

# Populate RAG database with 2.2M recipes
cd cli
python populate_rag_database.py

# Verify RAG system (check search functionality)
# Database will be automatically verified after population
```

### Hardware-Optimized Configurations

<details>
<summary>RTX 4090 (24GB VRAM) - Optimal Settings</summary>

```bash
# Full dataset training (4.5M+ recipes)
python train_recipe_model.py \
  --model-type t5 \
  --pretrained-model google/flan-t5-large \
  --epochs 3 \
  --batch-size 16 \
  --gradient-accumulation-steps 4 \
  --max-length 512 \
  --datasets recipe_nlg food_com_recipes_2m allrecipes_250k food_recipes_8k \
  --model-output ../models/recipe_generation_full

# Memory-efficient training
python train_recipe_model.py \
  --model-type t5 \
  --pretrained-model google/flan-t5-base \
  --epochs 8 \
  --batch-size 32 \
  --max-length 512
```

</details>

## ğŸ”§ API Documentation

### ğŸ¯ Core Endpoints

#### Recipe Management
```http
GET    /api/v1/recipes              # List recipes with filters
POST   /api/v1/recipes              # Create new recipe
GET    /api/v1/recipes/{id}         # Get recipe details
PUT    /api/v1/recipes/{id}         # Update recipe
DELETE /api/v1/recipes/{id}         # Delete recipe
POST   /api/v1/recipes/generate     # Enhanced AI recipe generation
```

#### ğŸ” RAG + MCP Enhanced Features
```http
POST   /api/v1/recipes/generate/enhanced  # RAG-enhanced recipe generation
POST   /api/v1/search/hybrid             # Hybrid semantic + keyword search
POST   /api/v1/knowledge/ingredients     # Ingredient substitution knowledge
POST   /api/v1/knowledge/techniques      # Cooking technique recommendations
POST   /api/v1/tools/nutrition          # Comprehensive nutrition analysis
POST   /api/v1/tools/meal-planning      # AI-powered meal planning
POST   /api/v1/tools/shopping-list      # Optimized shopping list generation
```

#### ğŸ¥ Health & Monitoring
```http
GET    /health                      # Basic health check
GET    /health/detailed             # Comprehensive health status
GET    /health/services             # All service health status
GET    /health/mcp                  # MCP server status
GET    /health/rag                  # RAG system status
GET    /health/metrics              # System resource metrics
GET    /health/alerts               # Current system alerts
POST   /health/refresh              # Force refresh health checks
```

#### ğŸ”— MCP Server Endpoints
```http
# Recipe Generation Server (Port 8001)
POST   /tools/generate_recipe       # T5-Large recipe generation
POST   /tools/validate_recipe       # Recipe validation
POST   /tools/enhance_recipe        # Recipe enhancement suggestions

# Knowledge Server (Port 8002)  
POST   /tools/search_recipes        # Vector similarity search
POST   /tools/get_substitutions     # Ingredient substitution recommendations
POST   /tools/get_techniques        # Cooking technique knowledge
POST   /tools/food_safety          # Food safety recommendations

# Tool Server (Port 8003)
POST   /tools/analyze_nutrition     # Nutrition analysis
POST   /tools/plan_meals           # Meal planning
POST   /tools/generate_shopping_list # Shopping list optimization
POST   /tools/wine_pairing         # Wine pairing suggestions
```

#### ğŸ¦€ Rust Performance & Monitoring
```http
# Performance endpoints with Rust acceleration
GET    /api/v1/rust/status          # Rust core status and availability
GET    /api/v1/rust/stats           # Performance statistics  
POST   /api/v1/rust/benchmark       # Performance benchmarks
GET    /api/v1/rust/health          # Health check

# Model drift detection endpoints
GET    /api/v1/monitoring/drift/status        # Drift monitoring system status
GET    /api/v1/monitoring/drift/report        # Comprehensive drift report
POST   /api/v1/monitoring/drift/detect        # Manual drift detection
POST   /api/v1/monitoring/drift/detect/recipes # Recipe generation drift analysis
GET    /api/v1/monitoring/drift/alerts        # Drift alert history
POST   /api/v1/monitoring/drift/baseline/training # Set training baseline
```

### ğŸ” Authentication
```http
POST   /api/v1/auth/login           # User login
POST   /api/v1/auth/register        # User registration  
POST   /api/v1/auth/refresh         # Refresh JWT token
```

**Authorization Header**: `Authorization: Bearer <jwt-token>`

## ğŸ§ª Testing & Quality Assurance

### ğŸ” MCP System Testing
```bash
# Test all MCP servers
make -f Makefile.mcp test-mcp

# Test specific components
curl -X POST http://localhost:8001/tools/generate_recipe \
  -H "Content-Type: application/json" \
  -d '{
    "ingredients": ["chicken", "rice", "broccoli"],
    "cuisine": "Asian",
    "dietary_restrictions": ["healthy"]
  }'

# Test RAG search
curl -X POST http://localhost:8002/tools/search_recipes \
  -H "Content-Type: application/json" \
  -d '{
    "query": "healthy chicken recipes",
    "top_k": 5
  }'

# Test system health
make -f Makefile.mcp health
```

### ğŸ¦€ Rust Performance Testing
```bash
# Test Rust core installation and performance
python test_rust_integration.py

# Benchmark Rust vs Python performance
curl -X POST http://localhost:8000/api/v1/rust/benchmark \
  -H "Content-Type: application/json" \
  -d '{
    "operation": "inference",
    "iterations": 100
  }'

# Test drift detection
curl -X POST http://localhost:8000/api/v1/monitoring/drift/detect/recipes \
  -H "Content-Type: application/json" \
  -d '{
    "recipes": [
      {
        "title": "Test Recipe",
        "ingredients": ["chicken", "rice"],
        "instructions": ["Cook chicken", "Add rice"]
      }
    ]
  }'

# Install Rust acceleration
python install_rust_core.py

# Build Rust core manually
python build_rust_core.py
```

### ğŸ“Š Performance Benchmarking
```bash
# Run comprehensive benchmarks
make -f Makefile.mcp benchmark

# Load test with Apache Bench
ab -n 100 -c 10 -T application/json \
  -p test_recipe.json \
  http://localhost:8001/tools/generate_recipe

# Monitor real-time performance
make -f Makefile.mcp monitor
```

### ğŸ›¡ï¸ Quality Assurance
```bash
# Backend tests with MCP integration
cd backend
pytest tests/ -v --cov=app --cov-report=html

# Frontend tests with MCP endpoints
cd frontend
npm run test
npm run test:e2e

# Integration tests across all services
docker-compose -f docker-compose.mcp-full.yml exec backend pytest tests/integration/
```

## ğŸ“Š Database Schema

### PostgreSQL (Primary)
- **Users**: Authentication and user profiles
- **User Sessions**: Session management and preferences
- **Meal Plans**: Generated meal planning data
- **Analytics**: Usage tracking and performance metrics

### MongoDB (Recipe Data)
- **Recipes**: Complete recipe documents with metadata
- **Recipe Collections**: Curated recipe groups
- **User Favorites**: User-specific recipe collections
- **Training Data Cache**: Processed training examples

### Redis (Caching)
- **API Responses**: Cached API responses for performance
- **Session Storage**: User session data
- **Task Queue**: Celery task management
- **Model Predictions**: Cached AI model outputs

### Elasticsearch (Search)
- **Recipe Search Index**: Full-text search capabilities
- **Ingredient Mapping**: Advanced ingredient search
- **Cuisine Classification**: Cuisine-based filtering
- **Nutritional Search**: Search by nutritional criteria

## ğŸš€ Deployment & Production

### Production Docker Setup
```bash
# Build and deploy production environment
docker-compose -f docker-compose.prod.yml build
docker-compose -f docker-compose.prod.yml up -d

# Health checks
docker-compose -f docker-compose.prod.yml ps
curl http://localhost:8000/health
```

### Environment Configuration

<details>
<summary>Production Environment Variables</summary>

#### Backend (.env)
```env
# Database Configuration
DATABASE_URL=postgresql://user:password@postgres:5432/chefgenius
MONGODB_URL=mongodb://mongodb:27017/chefgenius
REDIS_URL=redis://redis:6379/0
ELASTICSEARCH_URL=http://elasticsearch:9200

# Security
SECRET_KEY=your-256-bit-secret-key-change-in-production
JWT_SECRET_KEY=your-jwt-secret-key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI Service Configuration
OPENAI_API_KEY=your-openai-api-key
HUGGINGFACE_API_KEY=your-huggingface-api-key

# Model Paths
RECIPE_MODEL_PATH=models/recipe_generation
SUBSTITUTION_MODEL_PATH=models/substitution
NUTRITION_MODEL_PATH=models/nutrition
VISION_MODEL_PATH=models/vision

# Performance
WORKERS=4
MAX_CONNECTIONS=100
CACHE_TTL=3600
```

#### Frontend (.env.local)
```env
NEXT_PUBLIC_API_URL=https://api.chefgenius.com
NEXT_PUBLIC_APP_NAME=ChefGenius
NEXT_PUBLIC_ENABLE_ANALYTICS=true
NEXT_PUBLIC_SENTRY_DSN=your-sentry-dsn
```

</details>

### Scaling & Performance
- **Horizontal Scaling**: Multiple backend instances with load balancer
- **Database Sharding**: MongoDB sharding for large recipe collections
- **CDN Integration**: Static asset delivery optimization
- **Caching Strategy**: Multi-layer caching (Redis, application, CDN)
- **GPU Scaling**: Model inference with GPU clusters

## ğŸ” Monitoring & Analytics

### Application Monitoring
- **Health Checks**: Automated endpoint monitoring
- **Performance Metrics**: Response time and throughput tracking
- **Error Tracking**: Comprehensive error logging and alerting
- **User Analytics**: Usage patterns and feature adoption

### ML Model Monitoring
- **Model Performance**: Accuracy and quality metrics tracking
- **Inference Latency**: Real-time performance monitoring with Rust acceleration
- **Data Drift Detection**: Statistical monitoring with KS tests, PSI, Jensen-Shannon divergence
- **Recipe Quality Tracking**: Automated assessment of generated recipe quality
- **A/B Testing**: Model version comparison and rollout

### Infrastructure Monitoring
- **Resource Usage**: CPU, memory, GPU utilization
- **Database Performance**: Query optimization and indexing
- **Cache Hit Rates**: Redis and application cache effectiveness
- **Network Performance**: API response times and throughput
- **Rust Performance**: PyO3 acceleration metrics and performance gains tracking

## ğŸ“ Project Structure

```
chef-genius/
â”œâ”€â”€ ğŸ”§ backend/                     # FastAPI backend service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/                # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ core/                  # Configuration and settings
â”‚   â”‚   â”œâ”€â”€ models/                # Database models (SQLAlchemy)
â”‚   â”‚   â”œâ”€â”€ services/              # Business logic and AI services
â”‚   â”‚   â”‚   â”œâ”€â”€ drift_monitoring.py # Model drift detection service
â”‚   â”‚   â”‚   â””â”€â”€ rust_integration.py # Rust performance integration
â”‚   â”‚   â”œâ”€â”€ schemas/               # Pydantic schemas
â”‚   â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                 # Backend container
â”‚   â””â”€â”€ alembic/                   # Database migrations
â”œâ”€â”€ ğŸ¨ frontend/                    # Next.js frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                   # App router pages
â”‚   â”‚   â”œâ”€â”€ components/            # Reusable React components
â”‚   â”‚   â”œâ”€â”€ hooks/                 # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ lib/                   # Utilities and configurations
â”‚   â”‚   â”œâ”€â”€ store/                 # State management
â”‚   â”‚   â””â”€â”€ types/                 # TypeScript type definitions
â”‚   â”œâ”€â”€ public/                    # Static assets
â”‚   â”œâ”€â”€ package.json               # Node.js dependencies
â”‚   â””â”€â”€ Dockerfile                 # Frontend container
â”œâ”€â”€ ğŸ¤– models/                      # AI/ML model storage
â”‚   â”œâ”€â”€ recipe_generation/         # Recipe generation models
â”‚   â”œâ”€â”€ substitution/              # Ingredient substitution models
â”‚   â”œâ”€â”€ nutrition/                 # Nutrition analysis models
â”‚   â”œâ”€â”€ vision/                    # Computer vision models
â”‚   â””â”€â”€ versions/                  # Model version management
â”œâ”€â”€ ğŸ¦€ chef_genius_core/            # Rust performance library
â”‚   â”œâ”€â”€ src/                       # Rust source code
â”‚   â”‚   â”œâ”€â”€ drift_detection.rs     # Statistical drift detection engine
â”‚   â”‚   â”œâ”€â”€ inference.rs           # High-performance ML inference
â”‚   â”‚   â”œâ”€â”€ vector_search.rs       # Fast vector similarity search
â”‚   â”‚   â””â”€â”€ lib.rs                 # PyO3 Python bindings
â”‚   â”œâ”€â”€ Cargo.toml                 # Rust dependencies
â”‚   â””â”€â”€ README.md                  # Rust core documentation
â”œâ”€â”€ âš™ï¸ cli/                         # Command-line tools and scripts
â”‚   â”œâ”€â”€ complete_optimized_training.py # Main enterprise training script
â”‚   â”œâ”€â”€ comprehensive_checkpoint_tester.py # Model testing with edge cases
â”‚   â”œâ”€â”€ enterprise_b2b_tokenizer.py # B2B commercial tokenizer
â”‚   â”œâ”€â”€ consumer_end_user_tokenizer.py # Consumer home cooking tokenizer
â”‚   â”œâ”€â”€ dual_tokenizer_manager.py  # Unified tokenizer management
â”‚   â”œâ”€â”€ incremental_training.py    # Continual learning
â”‚   â”œâ”€â”€ online_learning_pipeline.py # Real-time learning pipeline
â”‚   â”œâ”€â”€ model_versioning.py        # Model version management
â”‚   â”œâ”€â”€ catastrophic_forgetting_prevention.py # Advanced ML techniques
â”‚   â”œâ”€â”€ test_generation.py         # Model testing utilities
â”‚   â”œâ”€â”€ install_rust_core.py       # Rust core installation script
â”‚   â”œâ”€â”€ build_rust_core.py         # Rust core build automation
â”‚   â””â”€â”€ test_rust_integration.py   # Rust integration testing
â”œâ”€â”€ ğŸ“Š data/                        # Training datasets and cache
â”‚   â”œâ”€â”€ datasets/                  # Raw training data
â”‚   â”œâ”€â”€ processed/                 # Preprocessed training data
â”‚   â”œâ”€â”€ cache/                     # Training cache files
â”‚   â””â”€â”€ external/                  # External data sources
â”œâ”€â”€ ğŸ§ª tests/                       # Comprehensive test suites
â”‚   â”œâ”€â”€ backend/                   # Backend API tests
â”‚   â”œâ”€â”€ frontend/                  # Frontend component tests
â”‚   â”œâ”€â”€ integration/               # Integration tests
â”‚   â””â”€â”€ load/                      # Performance tests
â”œâ”€â”€ ğŸ“‹ docs/                        # Documentation
â”‚   â”œâ”€â”€ api/                       # API documentation
â”‚   â”œâ”€â”€ deployment/                # Deployment guides
â”‚   â””â”€â”€ development/               # Development guides
â”œâ”€â”€ ğŸ³ docker-compose.yml           # Development environment
â”œâ”€â”€ ğŸ³ docker-compose.prod.yml      # Production environment
â”œâ”€â”€ ğŸ³ docker-compose.test.yml      # Testing environment
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â””â”€â”€ ğŸ“„ package.json                 # Node.js workspace configuration
```

## ğŸ”§ Troubleshooting

### Common Issues and Solutions

<details>
<summary>ğŸ—„ï¸ Database Connection Issues</summary>

```bash
# Check service status
docker-compose ps

# Reset all databases
docker-compose down -v
docker-compose up -d

# Individual service restart
docker-compose restart postgres
docker-compose restart mongodb
```

</details>

<details>
<summary>ğŸ¤– Model Loading Issues</summary>

```bash
# Verify model files exist
ls -la models/recipe_generation/

# Test model loading
python cli/test_generation.py --model-dir models/recipe_generation

# Check GPU availability
python -c "import torch; print(torch.cuda.is_available())"

# Download pre-trained models
python cli/download_models.py --all
```

</details>

<details>
<summary>ğŸ”¨ Build and Compilation Issues</summary>

```bash
# Clear build caches
docker system prune -a
npm cache clean --force

# Rebuild specific service
docker-compose build --no-cache backend
docker-compose build --no-cache frontend

# Check logs for specific errors
docker-compose logs backend
docker-compose logs frontend
```

</details>

<details>
<summary>âš¡ Performance Issues</summary>

```bash
# Monitor resource usage
docker stats

# Check database performance
docker-compose exec postgres pg_stat_activity

# Optimize Elasticsearch
curl -X PUT localhost:9200/_settings -d '{"index.refresh_interval": "30s"}'

# Clear Redis cache
docker-compose exec redis redis-cli FLUSHALL
```

</details>

## ğŸ¤ Contributing

We welcome contributions to ChefGenius! Please follow our contribution guidelines:

### Development Workflow
1. **Fork** the repository
2. **Clone** your fork: `git clone https://github.com/N0tT1m/chef-genius-ai.git`
3. **Create** a feature branch: `git checkout -b feature/amazing-feature`
4. **Install** dependencies and setup development environment
5. **Make** your changes with proper testing
6. **Run** tests and linting: `npm run test && npm run lint`
7. **Commit** changes: `git commit -m 'feat: add amazing feature'`
8. **Push** to branch: `git push origin feature/amazing-feature`
9. **Create** a Pull Request with detailed description

### Code Standards
- **Python**: Black formatting, flake8 linting, mypy type checking
- **TypeScript**: ESLint, Prettier formatting, strict TypeScript
- **Testing**: Minimum 80% code coverage required
- **Documentation**: Update relevant documentation for new features
- **Commit Messages**: Follow conventional commit format

### Pull Request Guidelines
- Provide clear description of changes
- Include tests for new functionality
- Update documentation as needed
- Ensure all CI checks pass
- Request review from maintainers

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Hugging Face** for transformer models and datasets
- **PyTorch** team for the deep learning framework
- **FastAPI** for the excellent Python web framework
- **Next.js** team for the React framework
- **Open source community** for inspiration and contributions

## ğŸ“ Support & Contact

### Getting Help
- **ğŸ“– Documentation**: Check the `/docs` directory for detailed guides
- **ğŸ› Bug Reports**: [Create an issue](https://github.com/N0tT1m/chef-genius-ai/issues)
- **ğŸ’¡ Feature Requests**: [Submit an enhancement](https://github.com/N0tT1m/chef-genius-ai/issues)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/N0tT1m/chef-genius-ai/discussions)

### Community
- **Discord**: Join our development community
- **Twitter**: Follow [@ChefGeniusAI](https://twitter.com/chefgeniusai) for updates
- **Blog**: Read about new features and improvements

### Professional Support
For enterprise support, custom development, or consulting services, please contact us at support@chefgenius.com

---

<div align="center">

**ChefGenius** - Revolutionizing Culinary Experiences with AI ğŸš€

[![Star this repo](https://img.shields.io/github/stars/N0tT1m/chef-genius-ai?style=social)](https://github.com/N0tT1m/chef-genius-ai)
[![Follow on Twitter](https://img.shields.io/twitter/follow/chefgeniusai?style=social)](https://twitter.com/chefgeniusai)

*Built with â¤ï¸ by developers who love good food and great code*

</div>